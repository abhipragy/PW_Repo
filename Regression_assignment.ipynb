{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#1 What is Simple Linear Regression\n",
        "\n",
        "Simple Linear Regression is a statistical method used to model the relationship between two continuous variables. One variable, called the dependent variable (or response variable), is the one you are trying to predict or understand. The other variable, called the independent variable (or predictor variable), is the one you are using to make the prediction.\n",
        "\n",
        "In simple linear regression, we assume that the relationship between these two variables can be approximated by a straight line. The goal is to find the equation of this line that best fits the data. The equation of a straight line is typically written as:\n",
        "\n",
        "$Y = a + bX + \\epsilon$$Y = a + bX + \\epsilon$\n",
        "\n",
        "Where:\n",
        "\n",
        "$Y$$Y$ is the dependent variable.\n",
        "$X$$X$ is the independent variable.\n",
        "$a$$a$ is the y-intercept (the value of Y when X is 0).\n",
        "$b$$b$ is the slope of the line (how much Y changes for a one-unit change in X).\n",
        "$\\epsilon$$\\epsilon$ is the error term, which represents the part of Y that cannot be explained by X.\n",
        "The process of finding the best-fitting line involves estimating the values of $a$$a$ and $b$$b$ from the data. This is typically done using a method called \"least squares,\" which minimizes the sum of the squared differences between the actual Y values and the Y values predicted by the line.\n",
        "\n",
        "Once the values of $a$$a$ and $b$$b$ are estimated, you have a model that can be used to predict the value of the dependent variable for a given value of the independent variable.\n",
        "\n",
        "Simple linear regression is a fundamental technique in statistics and machine learning and is often used for tasks such as:\n",
        "\n",
        "Predicting sales based on advertising spending.\n",
        "Estimating the price of a house based on its size.\n",
        "Analyzing the relationship between temperature and ice cream sales.\n",
        "It's important to note that simple linear regression assumes a linear relationship between the variables and is not suitable for all types of data. If the relationship is non-linear, other regression techniques might be more appropriate."
      ],
      "metadata": {
        "id": "YJSIxGmK47uk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#2. What are the key assumptions of Simple Linear Regression\n",
        "\n",
        "Simple Linear Regression relies on several key assumptions about the data and the relationship between the variables. Violations of these assumptions can affect the validity and reliability of the regression results. Here are the main assumptions:\n",
        "\n",
        "Linearity: The relationship between the independent variable (X) and the dependent variable (Y) is linear. This means that the relationship can be best described by a straight line. You can visually inspect this assumption by creating a scatter plot of the data.\n",
        "Independence of Errors: The errors (residuals) are independent of each other. This means that the error for one observation does not influence the error for another observation. This assumption is often violated in time series data, where observations are collected sequentially.\n",
        "Homoscedasticity (Constant Variance of Errors): The variance of the errors is constant across all levels of the independent variable. In other words, the spread of the residuals should be roughly the same for all values of X. Heteroscedasticity (non-constant variance) can lead to biased standard errors and unreliable hypothesis tests.\n",
        "Normality of Errors: The errors are normally distributed. This assumption is particularly important for hypothesis testing and constructing confidence intervals. You can check this assumption by examining a histogram or a Q-Q plot of the residuals.\n",
        "No Multicollinearity (for multiple regression): Although not strictly an assumption for simple linear regression (which only has one independent variable), it's crucial for multiple linear regression. It states that the independent variables should not be highly correlated with each other. In simple linear regression, this is not a concern as there's only one predictor.\n",
        "It's important to check these assumptions before interpreting the results of a simple linear regression analysis. If the assumptions are violated, you might need to transform the data, use a different type of regression model, or employ other techniques to address the violations."
      ],
      "metadata": {
        "id": "pRzmnbIj5CII"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. What does the coefficient m represent in the equation Y=mX+c\n",
        "\n",
        "in the equation $Y = mX + c$$Y = mX + c$, the coefficient 'm' represents the slope of the line.\n",
        "\n",
        "The slope tells you how much the dependent variable ($Y$$Y$) changes for every one-unit increase in the independent variable ($X$$X$).\n",
        "\n",
        "In the context of simple linear regression, this 'm' is the same as the coefficient 'b' in the equation $Y = a + bX + \\epsilon$$Y = a + bX + \\epsilon$ that I mentioned earlier. It quantifies the linear relationship between your independent and dependent variables."
      ],
      "metadata": {
        "id": "_kjP5Cnq5JfE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#4.What does the intercept c represent in the equation Y=mX+c\n",
        "\n",
        "In the equation $Y = mX + c$$Y = mX + c$, the coefficient 'c' represents the y-intercept.\n",
        "\n",
        "The y-intercept is the value of the dependent variable ($Y$$Y$) when the independent variable ($X$$X$) is equal to 0.\n",
        "\n",
        "In the context of simple linear regression, this 'c' is the same as the coefficient 'a' in the equation $Y = a + bX + \\epsilon$$Y = a + bX + \\epsilon$ that I mentioned earlier. It represents the point where the regression line crosses the y-axis. However, it's important to note that in some real-world scenarios, an X value of 0 might not be meaningful or within the range of your data. In such cases, the intercept's interpretation should be considered within the context of the data."
      ],
      "metadata": {
        "id": "PAq1UUNo5Qdk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#5  How do we calculate the slope m in Simple Linear Regression\n",
        "\n",
        "In Simple Linear Regression, the slope ($m$$m$ or $b$$b$) is calculated using the following formula:\n",
        "\n",
        "$m = \\frac{\\sum{(x_i - \\bar{x})(y_i - \\bar{y})}}{\\sum{(x_i - \\bar{x})^2}}$$m = \\frac{\\sum{(x_i - \\bar{x})(y_i - \\bar{y})}}{\\sum{(x_i - \\bar{x})^2}}$\n",
        "\n",
        "Where:\n",
        "\n",
        "$x_i$$x_i$ represents the individual values of the independent variable.\n",
        "$\\bar{x}$$\\bar{x}$ represents the mean of the independent variable.\n",
        "$y_i$$y_i$ represents the individual values of the dependent variable.\n",
        "$\\bar{y}$$\\bar{y}$ represents the mean of the dependent variable.\n",
        "$\\sum{}$$\\sum{}$ represents the sum across all data points.\n",
        "This formula is derived using the principle of least squares, which aims to minimize the sum of the squared differences between the observed values and the values predicted by the regression line.\n",
        "\n",
        "Alternatively, the slope can also be calculated using the covariance and the variance:\n",
        "\n",
        "$m = \\frac{Cov(X, Y)}{Var(X)}$$m = \\frac{Cov(X, Y)}{Var(X)}$\n",
        "\n",
        "Where:\n",
        "\n",
        "$Cov(X, Y)$$Cov(X, Y)$ is the covariance between the independent and dependent variables.\n",
        "$Var(X)$$Var(X)$ is the variance of the independent variable.\n",
        "Both formulas will give you the same result for the slope in simple linear regression."
      ],
      "metadata": {
        "id": "SPFgppmT5Zk1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#6. What is the purpose of the least squares method in Simple Linear Regression\n",
        "The purpose of the least squares method in Simple Linear Regression is to find the best-fitting line that describes the linear relationship between the independent and dependent variables.\n",
        "\n",
        "Here's how it works:\n",
        "\n",
        "Define Residuals: For each data point, a \"residual\" is the vertical distance between the actual observed value of the dependent variable ($Y$$Y$) and the value predicted by the regression line ($\\hat{Y}$$\\hat{Y}$). In other words, it's the error in the prediction for that specific data point.\n",
        "Square the Residuals: To avoid positive and negative errors canceling each other out, each residual is squared. This gives a measure of the error's magnitude, regardless of its direction.\n",
        "Sum the Squared Residuals: The squared residuals for all data points are summed up. This sum represents the total error of the regression line across all observations.\n",
        "Minimize the Sum: The least squares method finds the values of the slope ($b$$b$) and the y-intercept ($a$$a$) for the regression line that minimize this sum of squared residuals. By minimizing this sum, the method ensures that the line is as close as possible to all the data points simultaneously.\n",
        "In essence, the least squares method provides a mathematical way to determine the unique line that minimizes the overall prediction error, making it the most representative linear model for the given data.\n"
      ],
      "metadata": {
        "id": "svJRCsig5kHa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "7. How is the coefficient of determination (R²) interpreted in Simple Linear Regression\n",
        "\n",
        "In Simple Linear Regression, the coefficient of determination, denoted as $R^2$$R^2$, is a statistical measure that represents the proportion of the variance in the dependent variable ($Y$$Y$) that is predictable from the independent variable ($X$$X$).\n",
        "\n",
        "Here's a breakdown of its interpretation:\n",
        "\n",
        "Range: $R^2$$R^2$ values range from 0 to 1.\n",
        "Interpretation:\n",
        "An $R^2$$R^2$ of 0 means that the independent variable does not explain any of the variance in the dependent variable. The regression model does not fit the data any better than a horizontal line at the mean of the dependent variable.\n",
        "An $R^2$$R^2$ of 1 means that the independent variable explains all of the variance in the dependent variable. The regression model perfectly fits the data, and all data points lie exactly on the regression line.\n",
        "An $R^2$$R^2$ between 0 and 1 indicates the proportion of variance in the dependent variable that is explained by the independent variable. For example, an $R^2$$R^2$ of 0.60 means that 60% of the variation in $Y$$Y$ can be explained by the linear relationship with $X$$X$. The remaining 40% is due to other factors or random error.\n",
        "In simpler terms, $R^2$$R^2$ tells you how well the regression model fits the observed data. A higher $R^2$$R^2$ generally indicates a better fit, meaning the model is more effective at explaining the variation in the dependent variable.\n",
        "\n",
        "It's important to note that a high $R^2$$R^2$ does not necessarily mean the model is good or that the relationship is causal. It only indicates the strength of the linear association between the variables within the given dataset. You should always consider $R^2$$R^2$ in conjunction with other diagnostic measures and the context of your data and research question.\n",
        "\n"
      ],
      "metadata": {
        "id": "OBSB0GRe5pRj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "8.  What is Multiple Linear Regression\n",
        "\n",
        "Multiple Linear Regression is an extension of Simple Linear Regression that is used to model the relationship between a single dependent variable and two or more independent variables.\n",
        "\n",
        "While simple linear regression uses one independent variable to predict a dependent variable ($Y = a + bX + \\epsilon$$Y = a + bX + \\epsilon$), multiple linear regression uses multiple independent variables ($X_1, X_2, ..., X_n$$X_1, X_2, ..., X_n$) to predict the dependent variable. The equation for multiple linear regression is:\n",
        "\n",
        "$Y = a + b_1X_1 + b_2X_2 + ... + b_nX_n + \\epsilon$$Y = a + b_1X_1 + b_2X_2 + ... + b_nX_n + \\epsilon$\n",
        "\n",
        "Where:\n",
        "\n",
        "$Y$$Y$ is the dependent variable.\n",
        "$a$$a$ is the y-intercept (the value of Y when all independent variables are 0).\n",
        "$b_1, b_2, ..., b_n$$b_1, b_2, ..., b_n$ are the coefficients for each independent variable ($X_1, X_2, ..., X_n$$X_1, X_2, ..., X_n$). Each coefficient represents the change in $Y$$Y$ for a one-unit increase in that specific independent variable, holding all other independent variables constant.\n",
        "$\\epsilon$$\\epsilon$ is the error term.\n",
        "Similar to simple linear regression, the goal of multiple linear regression is to find the values of the intercept ($a$$a$) and the coefficients ($b_1, b_2, ..., b_n$$b_1, b_2, ..., b_n$) that best fit the data. This is also typically done using the method of least squares, which minimizes the sum of the squared differences between the actual $Y$$Y$ values and the values predicted by the model.\n",
        "\n",
        "Multiple linear regression is a powerful tool for understanding how multiple factors simultaneously influence an outcome. It is widely used in various fields for tasks such as:\n",
        "\n",
        "Predicting house prices based on size, number of bedrooms, and location.\n",
        "Analyzing the factors affecting sales, such as advertising spending, price, and promotions.\n",
        "Estimating the impact of different training methods on employee performance.\n",
        "It's important to note that multiple linear regression has its own set of assumptions, including the ones from simple linear regression, plus the crucial assumption of no multicollinearity, which means that the independent variables should not be highly correlated with each other. Violations of these assumptions can affect the validity of the model.\n"
      ],
      "metadata": {
        "id": "9XEVBUS_5tCB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "9. What is the main difference between Simple and Multiple Linear Regression\n",
        "\n",
        "The main difference between Simple Linear Regression and Multiple Linear Regression lies in the number of independent variables used to predict the dependent variable.\n",
        "\n",
        "Simple Linear Regression: Uses one independent variable to predict the dependent variable. The relationship is modeled with a single predictor.\n",
        "Multiple Linear Regression: Uses two or more independent variables to predict the dependent variable. The relationship is modeled with multiple predictors simultaneously.\n",
        "In essence, Simple Linear Regression is a special case of Multiple Linear Regression where there is only one independent variable. Multiple Linear Regression allows for a more complex analysis of how multiple factors influence an outcome.\n"
      ],
      "metadata": {
        "id": "rCpaR9a350eJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "10 What are the key assumptions of Multiple Linear Regression"
      ],
      "metadata": {
        "id": "L_aPPsyT56Ll"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "11.  What is heteroscedasticity, and how does it affect the results of a Multiple Linear Regression model"
      ],
      "metadata": {
        "id": "lKxYK3396B3Y"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "06b1b10b"
      },
      "source": [
        "**Heteroscedasticity** (pronounced het-er-o-ske-das-tiss-ity) is a violation of one of the key assumptions of linear regression: the assumption of **homoscedasticity** (constant variance of errors).\n",
        "\n",
        "In simpler terms:\n",
        "\n",
        "*   **Homoscedasticity** means that the spread (variance) of the residuals (the differences between the observed values and the values predicted by the model) is roughly the same across all levels of the independent variables. Imagine a scatter plot of residuals versus predicted values, where the points are randomly scattered in a band of roughly equal width.\n",
        "\n",
        "*   **Heteroscedasticity** means that the spread (variance) of the residuals is **not** constant across all levels of the independent variables. The spread of the residuals changes as the values of the independent variables change. On a scatter plot of residuals versus predicted values, you might see the points forming a cone shape, where the spread of the residuals increases or decreases as the predicted values change.\n",
        "\n",
        "**How does heteroscedasticity affect the results of a Multiple Linear Regression model?**\n",
        "\n",
        "While heteroscedasticity **does not bias the estimated regression coefficients** (the values of $a$ and $b_i$), it **does affect the standard errors of the coefficients**. This has important implications:\n",
        "\n",
        "1.  **Biased Standard Errors:** The standard errors of the coefficients will be biased (either too large or too small). If the standard errors are biased, then hypothesis tests (like t-tests for the significance of individual coefficients) and confidence intervals will be unreliable.\n",
        "\n",
        "2.  **Unreliable Hypothesis Tests:** You might incorrectly conclude that a coefficient is statistically significant when it's not, or vice versa. This can lead to incorrect conclusions about the relationship between the independent variables and the dependent variable.\n",
        "\n",
        "3.  **Inaccurate Confidence Intervals:** The confidence intervals for the coefficients will be too wide or too narrow, making it difficult to estimate the true range of values for the population coefficients.\n",
        "\n",
        "4.  **Less Efficient Estimates:** While the coefficients are not biased, they are no longer the \"best linear unbiased estimators\" (BLUE) in the presence of heteroscedasticity. This means that there are other estimation methods that could provide more precise estimates.\n",
        "\n",
        "**In summary:** Heteroscedasticity does not invalidate the overall model fit (like $R^2$), but it undermines the reliability of the statistical inferences made about the individual coefficients.\n",
        "\n",
        "**How to detect and address heteroscedasticity:**\n",
        "\n",
        "*   **Graphical Methods:** Plotting the residuals against the predicted values or against each independent variable. Looking for patterns like cone shapes or fanning indicates heteroscedasticity.\n",
        "*   **Statistical Tests:** Tests like the Breusch-Pagan test or the White test can formally assess for heteroscedasticity.\n",
        "*   **Addressing Heteroscedasticity:**\n",
        "    *   **Transforming the dependent variable:** Applying a logarithmic or square root transformation to the dependent variable can sometimes stabilize the variance.\n",
        "    *   **Using weighted least squares (WLS):** WLS is a regression technique that gives less weight to observations with larger variances and more weight to observations with smaller variances.\n",
        "    *   **Using robust standard errors:** These are standard errors that are adjusted to be more robust to violations of the homoscedasticity assumption. This is a common approach in many statistical software packages.\n",
        "    *   **Adding missing variables:** Sometimes, heteroscedasticity is caused by an important variable that is not included in the model.\n",
        "\n",
        "It's crucial to address heteroscedasticity when performing linear regression to ensure that your statistical inferences are valid and reliable."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#12  How can you improve a Multiple Linear Regression model with high multicollinearity"
      ],
      "metadata": {
        "id": "Rs3i-eKV6TLO"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1e9c79e1"
      },
      "source": [
        "High multicollinearity occurs when two or more independent variables in a multiple linear regression model are highly correlated with each other. This can cause problems because it becomes difficult for the model to determine the individual contribution of each highly correlated variable to the prediction of the dependent variable. While multicollinearity doesn't bias the overall model predictions, it can lead to unstable and unreliable coefficient estimates.\n",
        "\n",
        "Here are several ways to improve a Multiple Linear Regression model with high multicollinearity:\n",
        "\n",
        "1.  **Identify the highly correlated variables:**\n",
        "    *   **Correlation Matrix:** Calculate and examine the correlation matrix of your independent variables. Look for pairs of variables with high absolute correlation coefficients (e.g., above 0.7 or 0.8).\n",
        "    *   **Variance Inflation Factor (VIF):** Calculate the VIF for each independent variable. VIF measures how much the variance of the estimated regression coefficient is increased due to multicollinearity. A common rule of thumb is that a VIF greater than 5 or 10 indicates significant multicollinearity.\n",
        "\n",
        "2.  **Address the multicollinearity:**\n",
        "    *   **Remove one of the highly correlated variables:** If two variables are highly correlated, you can often remove one of them without losing much predictive power, as the information they provide is largely redundant. Choose the variable to remove based on theoretical considerations, practical relevance, or which variable has a higher VIF.\n",
        "    *   **Combine the highly correlated variables:** If the highly correlated variables are conceptually related, you might be able to create a new composite variable (e.g., an index) that combines them. This reduces the number of predictors and eliminates the multicollinearity between the original variables.\n",
        "    *   **Principal Component Analysis (PCA):** PCA is a dimensionality reduction technique that can transform a set of correlated variables into a set of uncorrelated variables called principal components. You can then use these principal components as independent variables in your regression model.\n",
        "    *   **Ridge Regression or Lasso Regression:** These are regularization techniques that can handle multicollinearity by adding a penalty term to the least squares objective function. This penalty shrinks the coefficient estimates towards zero, which can stabilize them in the presence of multicollinearity.\n",
        "    *   **Collect more data:** Sometimes, multicollinearity is a result of having a limited dataset. With more data, the relationships between variables might become clearer, and the multicollinearity might decrease.\n",
        "    *   **Feature Selection:** Use feature selection methods to identify the most important independent variables and remove less important or highly correlated ones.\n",
        "\n",
        "3.  **Interpret the results cautiously:** Even after addressing multicollinearity, it's important to be cautious when interpreting the individual coefficient estimates of the remaining variables, especially if some level of multicollinearity persists. Focus more on the overall model fit and the collective impact of the independent variables.\n",
        "\n",
        "By identifying and addressing multicollinearity, you can obtain more reliable and interpretable coefficient estimates in your Multiple Linear Regression model."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#13  What are some common techniques for transforming categorical variables for use in regression models"
      ],
      "metadata": {
        "id": "OkIcertF6bbc"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a5ffdee0"
      },
      "source": [
        "# Common Techniques for Transforming Categorical Variables for Regression\n",
        "\n",
        "Regression models typically require numerical input. Categorical variables, which represent categories or groups, need to be transformed into a numerical format before they can be used in these models. Here are some common techniques:\n",
        "\n",
        "1.  **One-Hot Encoding:**\n",
        "    *   **How it works:** Creates a new binary (0 or 1) column for each unique category in the variable. A '1' in a column indicates that the observation belongs to that category, and a '0' indicates it does not.\n",
        "    *   **Pros:** Simple to understand and implement. Does not imply any ordinal relationship between categories.\n",
        "    *   **Cons:** Can lead to a large number of new columns (high dimensionality), especially if a categorical variable has many unique categories. This can increase computational complexity and potentially lead to the \"dummy variable trap\" (multicollinearity if the intercept is included and all dummy variables are used).\n",
        "    *   **When to use:** Suitable for nominal categorical variables (where there is no inherent order) and when the number of unique categories is relatively small. To avoid the dummy variable trap, you typically drop one of the dummy variable columns.\n",
        "\n",
        "2.  **Label Encoding:**\n",
        "    *   **How it works:** Assigns a unique integer to each category. For example, \"Red\" might be 0, \"Blue\" might be 1, and \"Green\" might be 2.\n",
        "    *   **Pros:** Simple and reduces dimensionality compared to one-hot encoding.\n",
        "    *   **Cons:** Implies an ordinal relationship between categories, which may not exist. The model might incorrectly interpret higher numbers as having a greater value or importance. This can negatively impact model performance if the categories are not truly ordinal.\n",
        "    *   **When to use:** Primarily for ordinal categorical variables (where there is a natural order, e.g., \"Low\", \"Medium\", \"High\").\n",
        "\n",
        "3.  **Ordinal Encoding:**\n",
        "    *   **How it works:** Similar to label encoding, but the integer assignment is based on the inherent order of the categories. You explicitly define the order.\n",
        "    *   **Pros:** Preserves the ordinal relationship between categories.\n",
        "    *   **Cons:** Requires knowing and specifying the correct order of categories.\n",
        "\n",
        "4.  **Target Encoding (Mean Encoding):**\n",
        "    *   **How it works:** Replaces each category with the mean of the dependent variable for that category.\n",
        "    *   **Pros:** Can capture the relationship between the categorical variable and the dependent variable. Reduces dimensionality.\n",
        "    *   **Cons:** Can lead to overfitting, especially on small datasets or with categories that have few observations. Can be susceptible to outliers. Requires careful handling (e.g., using cross-validation or adding smoothing) to prevent overfitting.\n",
        "\n",
        "5.  **Frequency Encoding:**\n",
        "    *   **How it works:** Replaces each category with the frequency or count of that category in the dataset.\n",
        "    *   **Pros:** Simple and reduces dimensionality.\n",
        "    *   **Cons:** Does not capture the relationship with the dependent variable. Categories with the same frequency will be assigned the same value, even if their relationship with the dependent variable is different.\n",
        "\n",
        "6.  **Binary Encoding:**\n",
        "    *   **How it works:** Converts each category into a binary code. It first converts the category to an integer (like label encoding) and then represents that integer in binary form. Each bit in the binary code becomes a new column.\n",
        "    *   **Pros:** Reduces dimensionality compared to one-hot encoding, especially for variables with many categories.\n",
        "    *   **Cons:** The resulting binary columns are not easily interpretable.\n",
        "\n",
        "The choice of technique depends on the nature of the categorical variable (nominal or ordinal), the number of unique categories, the size of the dataset, and the specific regression model being used. It's often a good practice to experiment with different encoding techniques and evaluate their impact on model performance."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "YMVCYytR6hTr"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b17e37ee"
      },
      "source": [
        "# What is the role of interaction terms in Multiple Linear Regression?\n",
        "\n",
        "In Multiple Linear Regression, interaction terms are used to model situations where the effect of one independent variable on the dependent variable depends on the value of another independent variable. In other words, they allow you to assess whether the relationship between a predictor and the outcome changes based on the level of another predictor.\n",
        "\n",
        "Without an interaction term, a standard multiple linear regression model assumes that the effect of each independent variable on the dependent variable is constant, regardless of the values of the other independent variables. For example, if you are predicting salary based on years of experience and education level, a model without an interaction term would assume that the increase in salary for each additional year of experience is the same for someone with a high school diploma as it is for someone with a PhD.\n",
        "\n",
        "**How interaction terms work:**\n",
        "\n",
        "An interaction term is typically created by multiplying two independent variables together. If you have two independent variables, $X_1$ and $X_2$, the interaction term would be $X_1 * X_2$. The multiple linear regression equation with an interaction term would look like this:\n",
        "\n",
        "$Y = a + b_1X_1 + b_2X_2 + b_3(X_1 * X_2) + \\epsilon$\n",
        "\n",
        "Where:\n",
        "\n",
        "*   $Y$ is the dependent variable.\n",
        "*   $a$ is the intercept.\n",
        "*   $b_1$ is the coefficient for $X_1$.\n",
        "*   $b_2$ is the coefficient for $X_2$.\n",
        "*   $b_3$ is the coefficient for the interaction term ($X_1 * X_2$).\n",
        "\n",
        "**Interpreting the coefficient of an interaction term ($b_3$):**\n",
        "\n",
        "The coefficient $b_3$ represents the **change in the slope of the relationship between $Y$ and $X_1$ for a one-unit increase in $X_2$ (or vice versa)**.\n",
        "\n",
        "Let's revisit the salary example:\n",
        "\n",
        "$Salary = a + b_1(\\text{Years of Experience}) + b_2(\\text{Education Level}) + b_3(\\text{Years of Experience} * \\text{Education Level}) + \\epsilon$\n",
        "\n",
        "In this model:\n",
        "\n",
        "*   $b_1$ would represent the change in salary for one additional year of experience when education level is 0 (if education level is a categorical variable coded appropriately).\n",
        "*   $b_2$ would represent the change in salary for a one-unit increase in education level when years of experience is 0.\n",
        "*   $b_3$ would represent how the effect of years of experience on salary changes for each one-unit increase in education level. A significant positive $b_3$ would suggest that the return on experience is higher for individuals with higher education levels.\n",
        "\n",
        "**Why use interaction terms?**\n",
        "\n",
        "*   **Capture complex relationships:** They allow the model to capture more nuanced and realistic relationships between variables that are not simply additive.\n",
        "*   **Improved model fit:** Including relevant interaction terms can improve the overall fit of the model and explain more of the variance in the dependent variable.\n",
        "*   **Better understanding of the data:** They can provide valuable insights into how different factors combine to influence the outcome.\n",
        "\n",
        "**Considerations when using interaction terms:**\n",
        "\n",
        "*   **Interpretability:** Models with interaction terms can be more complex to interpret than models without them.\n",
        "*   **Multicollinearity:** Adding interaction terms can sometimes introduce or exacerbate multicollinearity, especially if the original variables are already correlated. It's often recommended to center the independent variables before creating interaction terms to reduce multicollinearity.\n",
        "*   **Theoretical basis:** It's generally best to include interaction terms that have a theoretical basis or are suggested by domain knowledge, rather than blindly adding all possible interactions.\n",
        "\n",
        "In summary, interaction terms are a valuable tool in Multiple Linear Regression for modeling conditional relationships between independent variables and the dependent variable, leading to a more accurate and insightful model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "376ece3b"
      },
      "source": [
        "# 15 How can the interpretation of the intercept differ between Simple and Multiple Linear Regression?\n",
        "\n",
        "While the mathematical definition of the intercept remains the same in both Simple and Multiple Linear Regression – it's the predicted value of the dependent variable when all independent variables are equal to zero – its **practical interpretation** can differ significantly due to the presence of multiple predictors in the latter.\n",
        "\n",
        "Here's a breakdown of the difference:\n",
        "\n",
        "**Simple Linear Regression:**\n",
        "\n",
        "In Simple Linear Regression ($Y = a + bX + \\epsilon$), the intercept ($a$) represents the predicted value of the dependent variable ($Y$) when the *single* independent variable ($X$) is zero.\n",
        "\n",
        "*   **Interpretation:** The interpretation is straightforward: it's the baseline value of $Y$ when $X$ has no influence (i.e., its value is 0).\n",
        "*   **Meaningfulness:** The meaningfulness of the intercept's interpretation depends entirely on whether $X=0$ is a plausible or relevant value in the context of your data.\n",
        "    *   If $X=0$ is a meaningful value within the range of your data (e.g., predicting height based on age, and age 0 is relevant), then the intercept has a direct and interpretable meaning.\n",
        "    *   If $X=0$ is outside the range of your data or is not a theoretically meaningful value (e.g., predicting income based on years of experience, and no one in your dataset has 0 years of experience, or it's not a relevant starting point), then the intercept might not have a practical interpretation on its own. It still plays a role in defining the regression line, but its value at $X=0$ may be an extrapolation.\n",
        "\n",
        "**Multiple Linear Regression:**\n",
        "\n",
        "In Multiple Linear Regression ($Y = a + b_1X_1 + b_2X_2 + ... + b_nX_n + \\epsilon$), the intercept ($a$) represents the predicted value of the dependent variable ($Y$) when *all* independent variables ($X_1, X_2, ..., X_n$) are simultaneously equal to zero.\n",
        "\n",
        "*   **Interpretation:** The interpretation becomes more complex because it requires all independent variables to be zero at the same time.\n",
        "*   **Meaningfulness:** The meaningfulness of the intercept's interpretation is often less direct than in simple linear regression.\n",
        "    *   It is highly dependent on whether a scenario where *all* independent variables are zero is a realistic or relevant situation in your data or in the real world.\n",
        "    *   In many cases, having all independent variables simultaneously at zero might be impossible, outside the range of your data, or theoretically nonsensical (e.g., predicting house price based on size, number of bedrooms, and location, where having a house with zero size, zero bedrooms, and a location value of zero is not meaningful).\n",
        "    *   Even if some independent variables can be zero, others might not be.\n",
        "\n",
        "**Key Differences Summarized:**\n",
        "\n",
        "*   **Number of variables at zero:** Simple regression requires only one independent variable to be zero for the intercept's interpretation, while multiple regression requires all independent variables to be zero.\n",
        "*   **Practical relevance:** The scenario where all independent variables are zero is often less practically relevant or even impossible in multiple regression compared to the single-variable case in simple regression.\n",
        "*   **Focus of interpretation:** In multiple regression, the focus of interpretation often shifts more towards the coefficients of the independent variables (which represent the change in Y for a one-unit change in that variable, holding others constant) rather than the intercept itself, especially if the \"all variables are zero\" scenario is not meaningful.\n",
        "\n",
        "Therefore, while the intercept is a necessary component of the regression equation in both cases, its practical interpretation as a meaningful baseline value is more likely to be valid and useful in Simple Linear Regression when X=0 is a relevant data point. In Multiple Linear Regression, the intercept's interpretation often needs to be considered with more caution and within the specific context of whether a scenario with all predictors at zero is meaningful."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e162c6d3"
      },
      "source": [
        "16  What is the significance of the slope in regression analysis, and how does it affect predictions?\n",
        "\n",
        "In regression analysis (both simple and multiple), the **slope** (represented by 'b' in $Y = a + bX + \\epsilon$ or $b_i$ for each independent variable $X_i$ in multiple regression) is a coefficient that quantifies the estimated change in the dependent variable ($Y$) for a one-unit increase in the corresponding independent variable ($X$), while holding other independent variables constant (in the case of multiple regression).\n",
        "\n",
        "**Significance of the Slope:**\n",
        "\n",
        "The significance of the slope coefficient is assessed through statistical tests, typically a t-test. The p-value associated with the slope coefficient indicates the probability of observing a slope as large as (or larger than) the estimated slope if there were truly no linear relationship between the independent and dependent variables in the population.\n",
        "\n",
        "*   **Statistically Significant Slope (typically p < 0.05):** If the slope is statistically significant, it suggests that there is a statistically meaningful linear relationship between the independent variable and the dependent variable. This means that the independent variable is a significant predictor of the dependent variable.\n",
        "*   **Statistically Non-Significant Slope (typically p >= 0.05):** If the slope is not statistically significant, it suggests that the observed linear relationship in the sample is likely due to random chance, and there may not be a true linear relationship between the variables in the population. In such cases, the independent variable is not considered a significant predictor in the model.\n",
        "\n",
        "The sign of the slope (positive or negative) indicates the direction of the relationship:\n",
        "\n",
        "*   **Positive Slope:** A positive slope means that as the independent variable increases, the dependent variable is expected to increase as well. There is a positive linear relationship.\n",
        "*   **Negative Slope:** A negative slope means that as the independent variable increases, the dependent variable is expected to decrease. There is a negative linear relationship.\n",
        "\n",
        "The magnitude of the slope indicates the strength of the relationship in terms of the expected change in Y for a unit change in X. A larger absolute value of the slope indicates a steeper line and a stronger expected impact of the independent variable on the dependent variable.\n",
        "\n",
        "**How the Slope Affects Predictions:**\n",
        "\n",
        "The estimated slope(s) are directly used in the regression equation to make predictions of the dependent variable for new, unseen values of the independent variable(s).\n",
        "\n",
        "The prediction equation is:\n",
        "\n",
        "$\\hat{Y} = \\hat{a} + \\hat{b}X$ (for simple linear regression)\n",
        "\n",
        "$\\hat{Y} = \\hat{a} + \\hat{b}_1X_1 + \\hat{b}_2X_2 + ... + \\hat{b}_nX_n$ (for multiple linear regression)\n",
        "\n",
        "Where $\\hat{Y}$ is the predicted value of the dependent variable, and $\\hat{a}$ and $\\hat{b}$ (or $\\hat{b}_i$) are the estimated intercept and slope(s) from the regression model.\n",
        "\n",
        "*   **Impact on Predictions:** The slope determines how much the predicted value of Y changes as the independent variable(s) change. A steeper slope will result in larger changes in predicted Y for a given change in X compared to a flatter slope.\n",
        "*   **Accuracy of Predictions:** If the slope is statistically significant and the model fits the data well (indicated by R² and other diagnostic measures), the slope contributes to making accurate predictions within the range of the data used to train the model.\n",
        "*   **Extrapolation:** It's important to be cautious when making predictions outside the range of the data (extrapolation), as the linear relationship observed within the data range may not hold true beyond it.\n",
        "\n",
        "In summary, the slope is a key coefficient in regression analysis that quantifies the linear relationship between variables. Its significance indicates whether this relationship is statistically meaningful, and its value directly influences how predictions are made using the regression model."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "17  How does the intercept in a regression model provide context for the relationship between variables\n",
        "\n",
        "The intercept in a regression model provides context by establishing a baseline for the dependent variable. Here's how:\n",
        "\n",
        "In essence, the intercept tells you the predicted value of the dependent variable when all independent variables in the model are equal to zero.\n",
        "\n",
        "Simple Linear Regression: In the case of simple linear regression with one independent variable ($Y = a + bX + \\epsilon$$Y = a + bX + \\epsilon$), the intercept ($a$$a$) is the predicted value of $Y$$Y$ when $X$$X$ is 0. If $X=0$$X=0$ is a meaningful value in your data (e.g., age 0 when predicting height), the intercept gives you a starting point or baseline value for $Y$$Y$ before the independent variable has any effect. If $X=0$$X=0$ is not meaningful, the intercept's practical interpretation might be limited, but it still anchors the regression line.\n",
        "Multiple Linear Regression: In multiple linear regression ($Y = a + b_1X_1 + b_2X_2 + ... + b_nX_n + \\epsilon$$Y = a + b_1X_1 + b_2X_2 + ... + b_nX_n + \\epsilon$), the intercept ($a$$a$) is the predicted value of $Y$$Y$ when all independent variables ($X_1, X_2, ..., X_n$$X_1, X_2, ..., X_n$) are simultaneously zero. Similar to the simple case, if this scenario (all predictors at zero) is meaningful in your context, the intercept provides a baseline value for $Y$$Y$ when none of the predictors have any influence. However, as we discussed, having all predictors at zero is often not a realistic scenario in multiple regression, so the intercept's direct interpretation as a baseline might be less practical.\n",
        "How it provides context:\n",
        "\n",
        "Baseline Value: It gives you a starting point for the dependent variable when the effects of the independent variables are removed (by setting them to zero).\n",
        "Anchoring the Line/Plane: Mathematically, the intercept is essential for defining the position of the regression line (or hyperplane in multiple regression) in the coordinate system. It's the point where the line/plane crosses the y-axis.\n",
        "Understanding the Model: Even if the intercept itself doesn't have a direct, practical interpretation in all cases, its value is necessary for the regression equation to accurately represent the relationship between the variables and make predictions. The slope(s) then describe how the dependent variable changes relative to this baseline established by the intercept.\n",
        "So, while the slopes tell you about the change in the dependent variable for a unit change in an independent variable, the intercept provides the level of the dependent variable when the independent variables are at their zero points. This baseline can be highly informative when the zero points are meaningful in the context of your data.The intercept in a regression model provides context by establishing a baseline for the dependent variable. Here's how:\n",
        "\n",
        "In essence, the intercept tells you the predicted value of the dependent variable when all independent variables in the model are equal to zero.\n",
        "\n",
        "Simple Linear Regression: In the case of simple linear regression with one independent variable ($Y = a + bX + \\epsilon$$Y = a + bX + \\epsilon$), the intercept ($a$$a$) is the predicted value of $Y$$Y$ when $X$$X$ is 0. If $X=0$$X=0$ is a meaningful value in your data (e.g., age 0 when predicting height), the intercept gives you a starting point or baseline value for $Y$$Y$ before the independent variable has any effect. If $X=0$$X=0$ is not meaningful, the intercept's practical interpretation might be limited, but it still anchors the regression line.\n",
        "Multiple Linear Regression: In multiple linear regression ($Y = a + b_1X_1 + b_2X_2 + ... + b_nX_n + \\epsilon$$Y = a + b_1X_1 + b_2X_2 + ... + b_nX_n + \\epsilon$), the intercept ($a$$a$) is the predicted value of $Y$$Y$ when all independent variables ($X_1, X_2, ..., X_n$$X_1, X_2, ..., X_n$) are simultaneously zero. Similar to the simple case, if this scenario (all predictors at zero) is meaningful in your context, the intercept provides a baseline value for $Y$$Y$ when none of the predictors have any influence. However, as we discussed, having all predictors at zero is often not a realistic scenario in multiple regression, so the intercept's direct interpretation as a baseline might be less practical.\n",
        "How it provides context:\n",
        "\n",
        "Baseline Value: It gives you a starting point for the dependent variable when the effects of the independent variables are removed (by setting them to zero).\n",
        "Anchoring the Line/Plane: Mathematically, the intercept is essential for defining the position of the regression line (or hyperplane in multiple regression) in the coordinate system. It's the point where the line/plane crosses the y-axis.\n",
        "Understanding the Model: Even if the intercept itself doesn't have a direct, practical interpretation in all cases, its value is necessary for the regression equation to accurately represent the relationship between the variables and make predictions. The slope(s) then describe how the dependent variable changes relative to this baseline established by the intercept.\n",
        "So, while the slopes tell you about the change in the dependent variable for a unit change in an independent variable, the intercept provides the level of the dependent variable when the independent variables are at their zero points. This baseline can be highly informative when the zero points are meaningful in the context of your data."
      ],
      "metadata": {
        "id": "TRSKnfAj7Shj"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3e07ad6f"
      },
      "source": [
        "#18 What are the limitations of using R² as a sole measure of model performance?\n",
        "\n",
        "While the coefficient of determination ($R^2$) is a widely used metric to assess the goodness-of-fit of a linear regression model, relying on it as the *sole* measure of model performance can be misleading. Here are some of the key limitations:\n",
        "\n",
        "1.  **R² always increases or stays the same when adding more independent variables:** Even if the new variable is not statistically significant or theoretically relevant, adding it to the model will never decrease the $R^2$. This can lead to overfitting, where the model fits the noise in the training data rather than the true underlying relationship. Adjusted R² helps to address this by penalizing the inclusion of unnecessary variables.\n",
        "\n",
        "2.  **High R² doesn't necessarily mean the model is good or appropriate:** A high $R^2$ can be achieved even if the model violates key assumptions of linear regression (e.g., linearity, homoscedasticity, normality of errors). If the assumptions are violated, the model's inferences and predictions may be unreliable, despite a high $R^2$.\n",
        "\n",
        "3.  **R² doesn't indicate the causal relationship:** $R^2$ measures the strength of the linear association between the independent variables and the dependent variable, but it does not imply causation. Correlation does not equal causation.\n",
        "\n",
        "4.  **R² doesn't tell you about the significance of individual predictors:** A high overall $R^2$ doesn't guarantee that all or even any of the individual independent variables are statistically significant predictors of the dependent variable. You need to examine the p-values of the individual coefficients to determine their significance.\n",
        "\n",
        "5.  **R² doesn't assess the predictive accuracy on new data:** A model with a high $R^2$ on the training data might perform poorly when predicting on new, unseen data (poor out-of-sample performance). This is related to the issue of overfitting. You should use techniques like cross-validation to assess how well your model generalizes to new data.\n",
        "\n",
        "6.  **R² can be misleading for non-linear relationships:** $R^2$ is designed to measure the proportion of variance explained by a *linear* relationship. If the true relationship between the variables is non-linear, a low $R^2$ might incorrectly suggest a weak relationship, or a high $R^2$ might be achieved by fitting a linear model to a non-linear pattern within a specific range of data.\n",
        "\n",
        "7.  **R² doesn't detect outliers or influential points:** Outliers and influential data points can significantly impact the regression results and inflate the $R^2$ without necessarily representing the overall trend of the data. Diagnostic plots are needed to identify such points.\n",
        "\n",
        "**In conclusion:** While $R^2$ is a useful starting point for evaluating a regression model, it should always be considered in conjunction with other metrics and diagnostic checks, such as:\n",
        "\n",
        "*   Adjusted R²\n",
        "*   P-values of individual coefficients\n",
        "*   Residual plots (to check for linearity, homoscedasticity, and outliers)\n",
        "*   Normality tests of residuals\n",
        "*   Evaluation on a separate test set or using cross-validation\n",
        "*   Theoretical understanding of the relationship between variables\n",
        "\n",
        "A holistic evaluation considering these factors provides a more complete and reliable assessment of the model's performance and validity."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#19  How would you interpret a large standard error for a regression coefficient\n",
        "\n",
        "A large standard error for a regression coefficient is an important indicator. Here's how you would interpret it:\n",
        "\n",
        "In regression analysis, the standard error of a coefficient is a measure of the variability or uncertainty of the estimated coefficient. It tells you how much the estimated coefficient is likely to vary if you were to repeat the sampling and modeling process with different datasets from the same population.\n",
        "\n",
        "A large standard error for a regression coefficient indicates:\n",
        "\n",
        "Low Precision of the Estimate: The estimated coefficient is less precise. This means that the true value of the population coefficient could be quite far from the estimated value in your sample.\n",
        "Wider Confidence Interval: The confidence interval for the coefficient will be wider. A wider confidence interval reflects greater uncertainty about the true value of the coefficient in the population. For example, a 95% confidence interval might be very broad, suggesting that we are less certain about the exact impact of the independent variable on the dependent variable.\n",
        "Reduced Statistical Significance: A large standard error makes it less likely that the coefficient will be statistically significant. The t-statistic for a coefficient is calculated by dividing the estimated coefficient by its standard error ($t = \\frac{\\text{Coefficient}}{\\text{Standard Error}}$$t = \\frac{\\text{Coefficient}}{\\text{Standard Error}}$). If the standard error is large, the t-statistic will be smaller, and the p-value will be larger. A larger p-value means there is less evidence to reject the null hypothesis that the true population coefficient is zero.\n",
        "Potential Issues in the Model or Data: A large standard error can be a symptom of several issues, including:\n",
        "Multicollinearity: High correlation between independent variables can inflate the standard errors of their coefficients.\n",
        "Small Sample Size: With a small sample, there is less information to precisely estimate the coefficients, leading to larger standard errors.\n",
        "High Variability in the Data: If there is a lot of spread or noise in the relationship between the independent and dependent variables, it can result in larger standard errors.\n",
        "Model Misspecification: If the model is not correctly specified (e.g., missing important variables, incorrect functional form), it can affect the standard errors.\n",
        "In summary: A large standard error for a regression coefficient means that you should be cautious about the precise value and the statistical significance of that coefficient. It suggests that the model is less certain about the true impact of that particular independent variable. You would then want to investigate why the standard error is large and potentially address the underlying issue (e.g., check for multicollinearity, consider collecting more data if feasible)."
      ],
      "metadata": {
        "id": "YqbIhVCq7fmt"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "da38fbe4"
      },
      "source": [
        "20 How can heteroscedasticity be identified in residual plots, and why is it important to address it?\n",
        "\n",
        "**Identifying Heteroscedasticity in Residual Plots:**\n",
        "\n",
        "Residual plots are graphs that show the residuals (the differences between the observed values of the dependent variable and the values predicted by the regression model) on the y-axis and either the predicted values of the dependent variable or the independent variables on the x-axis.\n",
        "\n",
        "If the assumption of homoscedasticity (constant variance of errors) is met, the residual plot should show the residuals randomly scattered around zero with a roughly equal spread across the range of the x-axis. There should be no discernible pattern.\n",
        "\n",
        "However, if heteroscedasticity is present, the residual plot will show a pattern where the spread of the residuals changes as the values on the x-axis change. Common patterns indicating heteroscedasticity include:\n",
        "\n",
        "1.  **Cone Shape (Fanning Out or In):** The most common pattern is a cone shape, where the spread of the residuals either increases or decreases as the values on the x-axis increase.\n",
        "    *   **Fanning Out:** The residuals are clustered closely together at one end of the x-axis and spread out wider at the other end. This indicates that the variance of the errors increases as the independent variable(s) or predicted values increase.\n",
        "    *   **Fanning In:** The residuals are spread out wider at one end of the x-axis and cluster more closely together at the other end. This indicates that the variance of the errors decreases as the independent variable(s) or predicted values increase.\n",
        "\n",
        "2.  **Non-linear Patterns:** While not strictly a change in variance, any systematic non-linear pattern in the residuals (e.g., a curve) can sometimes be associated with heteroscedasticity or suggest that the linear model is not appropriate.\n",
        "\n",
        "**Example of a Residual Plot with Heteroscedasticity (Fanning Out):**\n",
        "\n",
        "Imagine a scatter plot where the x-axis is \"Predicted Sales\" and the y-axis is \"Residuals.\" If the plot shows that the residuals are very close to zero when predicted sales are low, but the spread of the residuals gets much wider as predicted sales increase, that's a clear sign of heteroscedasticity.\n",
        "\n",
        "**Why is it important to address heteroscedasticity?**\n",
        "\n",
        "As discussed before, while heteroscedasticity does not bias the estimated regression coefficients, it **does affect the standard errors of the coefficients**. This is important because:\n",
        "\n",
        "*   **Invalid Hypothesis Tests:** The standard errors are used to calculate t-statistics and p-values, which are used to test the statistical significance of the independent variables. With biased standard errors, your hypothesis tests will be unreliable. You might incorrectly conclude that a variable is significant when it's not, or miss a significant relationship.\n",
        "*   **Inaccurate Confidence Intervals:** The standard errors are also used to construct confidence intervals for the coefficients. Heteroscedasticity leads to inaccurate confidence intervals, making it difficult to determine the likely range of the true population coefficient.\n",
        "*   **Less Efficient Estimates:** The standard ordinary least squares (OLS) regression is not the most efficient estimation method in the presence of heteroscedasticity. More efficient methods exist that can provide more precise estimates.\n",
        "\n",
        "In summary, identifying and addressing heteroscedasticity is crucial for ensuring the validity of your statistical inferences and the reliability of your regression model's results. Ignoring heteroscedasticity means that you cannot fully trust the p-values and confidence intervals, which are essential for drawing conclusions about the relationships between your variables."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " 21 What does it mean if a Multiple Linear Regression model has a high R² but low adjusted R²\n",
        "\n",
        " A high R² and a low adjusted R² together indicate that your model likely includes independent variables that are not significantly contributing to explaining the variance in the dependent variable, and the model might be overfitting the training data.\n",
        "\n",
        "Here's a breakdown:\n",
        "\n",
        "R² (Coefficient of Determination): As we discussed, R² measures the proportion of the variance in the dependent variable that is predictable from the independent variables. When you add more independent variables to a multiple linear regression model, the R² will always increase or stay the same, regardless of whether the new variable is actually helpful or not. This is because R² simply measures how well the model fits the training data.\n",
        "Adjusted R²: Adjusted R² is a modified version of R² that accounts for the number of independent variables in the model and the sample size. It penalizes the inclusion of unnecessary independent variables. Unlike R², adjusted R² can decrease if you add an independent variable that does not improve the model's fit by a sufficient amount (relative to the penalty for including an extra variable).\n",
        "Interpretation of High R² and Low Adjusted R²:\n",
        "\n",
        "When you have a high R² but a significantly lower adjusted R², it suggests that:\n",
        "\n",
        "Some independent variables are not useful: The increase in R² is likely due to the inclusion of independent variables that are not truly related to the dependent variable in the population, but happen to improve the fit on your specific sample data.\n",
        "Overfitting: The model is fitting the noise or random fluctuations in the training data, rather than capturing the true underlying relationships. This means the model might perform well on the training data but will likely perform poorly when making predictions on new, unseen data.\n",
        "Model Complexity: The model is more complex than it needs to be to explain the variance in the dependent variable.\n",
        "In essence:\n",
        "\n",
        "A high R² tells you that your model fits the training data well.\n",
        "A low adjusted R² tells you that this good fit on the training data might be due to including too many predictors that don't have real predictive power in the population, and the model might not generalize well to new data.\n",
        "What to do if you see this:\n",
        "\n",
        "Examine individual predictor significance: Check the p-values of your independent variables. Variables with high p-values are likely not statistically significant and may be candidates for removal.\n",
        "Consider feature selection techniques: Use methods like stepwise regression, Lasso, or Ridge regression (which we briefly mentioned when discussing multicollinearity) to identify the most important predictors and potentially remove less important ones.\n",
        "Validate your model on new data: Always evaluate your model's performance on a separate test set or using cross-validation to see how well it generalizes beyond the training data. The adjusted R² gives you an indication of this, but out-of-sample performance metrics are more direct.\n",
        "Understanding the difference between R² and adjusted R² is crucial for building robust and generalizable regression models.\n"
      ],
      "metadata": {
        "id": "vZru99gF9HCo"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0f04d263"
      },
      "source": [
        "#22 Why is it important to scale variables in Multiple Linear Regression?\n",
        "\n",
        "While not strictly a requirement for the core Ordinary Least Squares (OLS) estimation in Multiple Linear Regression to produce unbiased coefficients, scaling variables is often a recommended preprocessing step for several important reasons:\n",
        "\n",
        "1.  **Impact on Regularization Techniques (Lasso, Ridge, Elastic Net):**\n",
        "    *   Regularization methods penalize the size of the coefficients to prevent overfitting.\n",
        "    *   If variables are on different scales, the penalty will disproportionately affect variables with larger scales, even if they are not necessarily less important.\n",
        "    *   Scaling ensures that all coefficients are penalized equally based on their actual contribution to the model, leading to more effective regularization and better model performance.\n",
        "\n",
        "2.  **Easier Interpretation of Coefficients (Magnitude Comparison):**\n",
        "    *   When variables are on vastly different scales (e.g., one variable is in dollars and another is in years), comparing the magnitudes of their coefficients directly is not meaningful.\n",
        "    *   Scaling brings all variables to a similar scale (e.g., mean of 0 and standard deviation of 1). After scaling, the magnitude of the coefficients can be more easily compared to understand the relative impact of each independent variable on the dependent variable. A larger absolute coefficient value for a scaled variable suggests a stronger influence on the dependent variable.\n",
        "\n",
        "3.  **Gradient Descent Optimization:**\n",
        "    *   If you are using optimization algorithms like Gradient Descent (which is often the case for more complex regression models or when regularization is applied), unscaled variables can lead to an elongated cost function surface.\n",
        "    *   This elongated surface can make the optimization process slower and more difficult to converge to the optimal solution.\n",
        "    *   Scaling creates a more spherical cost function surface, allowing Gradient Descent to converge more quickly and efficiently.\n",
        "\n",
        "4.  **Influence of Outliers (for some scaling methods):**\n",
        "    *   Some scaling methods, like Standardization (Z-score scaling), are sensitive to outliers. Outliers can disproportionately affect the mean and standard deviation, which are used in the scaling process.\n",
        "    *   While this isn't a reason *to* scale, it's a consideration *when* scaling. Robust scaling methods (like RobustScaler in scikit-learn) are less affected by outliers.\n",
        "\n",
        "5.  **Algorithms Sensitive to Feature Scaling:**\n",
        "    *   While OLS linear regression is generally not as sensitive to feature scaling as some other algorithms (like Support Vector Machines, K-Nearest Neighbors, or principal component analysis), it's still a good practice, especially if you plan to explore other models or use regularization.\n",
        "\n",
        "**Common Scaling Techniques:**\n",
        "\n",
        "*   **Standardization (Z-score normalization):** Transforms data to have a mean of 0 and a standard deviation of 1. Formula: $x_{scaled} = (x - \\mu) / \\sigma$.\n",
        "*   **Normalization (Min-Max scaling):** Transforms data to a fixed range, usually between 0 and 1. Formula: $x_{scaled} = (x - x_{min}) / (x_{max} - x_{min})$.\n",
        "\n",
        "In summary, while OLS linear regression can technically work with unscaled data, scaling is highly recommended, especially if you are using regularization, want to compare coefficient magnitudes, or employing optimization algorithms like Gradient Descent. It helps improve model performance, interpretability, and the efficiency of the training process."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dd3a1897"
      },
      "source": [
        "#23 What is Polynomial Regression?\n",
        "\n",
        "Polynomial Regression is a form of regression analysis in which the relationship between the independent variable ($X$) and the dependent variable ($Y$) is modeled as an **n-th degree polynomial** in $X$. While linear regression models the relationship as a straight line, polynomial regression allows you to fit a curve to your data.\n",
        "\n",
        "The equation for a simple linear regression is:\n",
        "$Y = a + bX + \\epsilon$\n",
        "\n",
        "The equation for a polynomial regression of degree $n$ is:\n",
        "$Y = a + b_1X + b_2X^2 + ... + b_nX^n + \\epsilon$\n",
        "\n",
        "Where:\n",
        "\n",
        "*   $Y$ is the dependent variable.\n",
        "*   $X$ is the independent variable.\n",
        "*   $a$ is the y-intercept.\n",
        "*   $b_1, b_2, ..., b_n$ are the coefficients for each power of $X$.\n",
        "*   $\\epsilon$ is the error term.\n",
        "\n",
        "**Key Concepts:**\n",
        "\n",
        "*   **Degree of the Polynomial:** The degree ($n$) determines the complexity of the curve.\n",
        "    *   Degree 1: Simple linear regression (a straight line).\n",
        "    *   Degree 2: Quadratic relationship (a parabola).\n",
        "    *   Degree 3: Cubic relationship, and so on.\n",
        "*   **Linear in Coefficients:** Although the relationship between $X$ and $Y$ is non-linear, polynomial regression is still considered a form of *linear* regression because the model is linear in the coefficients ($a, b_1, ..., b_n$). This means that the coefficients are estimated using linear techniques like Ordinary Least Squares (OLS).\n",
        "*   **Transforming the Feature:** Polynomial regression essentially involves creating new features by raising the original independent variable to different powers ($X^2, X^3$, etc.) and then fitting a linear model to these new features.\n",
        "\n",
        "**Why use Polynomial Regression?**\n",
        "\n",
        "*   **Modeling Non-linear Relationships:** It is useful when the relationship between the variables is clearly not linear and a straight line does not adequately capture the pattern in the data.\n",
        "*   **Flexibility:** By increasing the degree of the polynomial, you can fit more complex curves to the data.\n",
        "\n",
        "**Considerations and Drawbacks:**\n",
        "\n",
        "*   **Overfitting:** Choosing a high degree polynomial can lead to overfitting, especially with limited data. An overly complex model will fit the noise in the training data and perform poorly on new, unseen data.\n",
        "*   **Interpretation:** Interpreting the coefficients of higher-degree polynomial terms can be less intuitive than interpreting the slope in simple linear regression.\n",
        "*   **Extrapolation:** Polynomial models can produce highly erratic and unreliable predictions when extrapolating outside the range of the data used to train the model.\n",
        "\n",
        "**When to use it:**\n",
        "\n",
        "Polynomial regression can be a good option when:\n",
        "\n",
        "*   There is a clear non-linear pattern in the data that can be approximated by a polynomial curve.\n",
        "*   You have a theoretical reason to believe that a polynomial relationship exists.\n",
        "\n",
        "It's important to choose the degree of the polynomial carefully, often by evaluating the model's performance on a validation set or using techniques like cross-validation to avoid overfitting."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "24. How does polynomial regression differ from linear regression"
      ],
      "metadata": {
        "id": "iI9ZyZWA-y9L"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "919ca61a"
      },
      "source": [
        "# How does polynomial regression differ from linear regression?\n",
        "\n",
        "The core difference between Simple Linear Regression and Polynomial Regression lies in the **nature of the relationship** they model between the independent variable(s) and the dependent variable.\n",
        "\n",
        "Here's a breakdown of the key differences:\n",
        "\n",
        "| Feature            | Simple Linear Regression             | Polynomial Regression                 |\n",
        "| :----------------- | :----------------------------------- | :------------------------------------ |\n",
        "| **Relationship Modeled** | Linear (straight line)               | Non-linear (curve)                    |\n",
        "| **Equation Form**    | $Y = a + bX + \\epsilon$              | $Y = a + b_1X + b_2X^2 + ... + b_nX^n + \\epsilon$ |\n",
        "| **Number of Independent Variables** | One (in its simplest form)           | Can involve one independent variable raised to different powers, or multiple independent variables with polynomial terms and potentially interaction terms. |\n",
        "| **Flexibility**    | Less flexible, assumes a straight line relationship. | More flexible, can fit curves to the data. |\n",
        "| **Ability to Capture Complex Patterns** | Limited to linear patterns.          | Can capture more complex, non-linear patterns. |\n",
        "| **Risk of Overfitting** | Lower risk of overfitting (for a single predictor). | Higher risk of overfitting, especially with high-degree polynomials or limited data. |\n",
        "| **Interpretation of Coefficients** | Slope has a straightforward interpretation (change in Y for unit change in X). | Interpretation of coefficients for higher-order terms can be less intuitive. |\n",
        "| **Extrapolation**  | Generally more reliable for extrapolation (within reason) compared to high-degree polynomial models. | Can produce highly erratic and unreliable predictions when extrapolating outside the training data range. |\n",
        "| **Underlying Principle** | Still uses linear techniques (like OLS) to estimate coefficients, but on transformed features ($X, X^2, ...$). |\n",
        "\n",
        "**In essence:**\n",
        "\n",
        "*   **Linear Regression** is suitable when you believe a straight-line relationship exists between the variables.\n",
        "*   **Polynomial Regression** is used when the relationship is non-linear and can be better represented by a curve.\n",
        "\n",
        "Polynomial regression can be seen as an extension of linear regression where you create new features by taking powers of the original independent variable(s) and then fit a linear model to these new features. This allows the model to capture the curvature in the data."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "25 When is polynomial regression used\n",
        "\n",
        "Polynomial regression is used when the relationship between the independent variable(s) and the dependent variable is not linear and appears to follow a curved pattern.\n",
        "\n",
        "Here are some specific scenarios when you might consider using polynomial regression:\n",
        "\n",
        "When Scatter Plots Show a Curved Relationship: The most common indicator is when a scatter plot of your data reveals a clear non-linear pattern that a straight line would not fit well. This could be a U-shape, an inverted U-shape, or other curves.\n",
        "Theoretical Basis for a Non-linear Relationship: Sometimes, domain knowledge or the underlying theory suggests that the relationship between variables is inherently non-linear. For example, the relationship between temperature and the efficiency of a chemical reaction might be non-linear.\n",
        "Modeling Curvature in Data: Polynomial regression allows you to explicitly model the curvature in your data by including higher-order terms of the independent variable(s).\n",
        "When Linear Regression Residuals Show a Pattern: If you initially fit a linear regression model and the residual plot shows a systematic non-linear pattern (like a curve or a U-shape), it suggests that the linear model is not capturing the relationship adequately, and a polynomial model might be more appropriate.\n",
        "Examples of potential use cases:\n",
        "\n",
        "Modeling the relationship between the dosage of a drug and its effectiveness, where the effect might increase up to a certain point and then decrease.\n",
        "Predicting the trajectory of a projectile.\n",
        "Modeling growth curves that are not strictly linear.\n",
        "Analyzing the relationship between age and certain physical or cognitive abilities, which might not be linear throughout the lifespan.\n",
        "It's important to remember the potential drawbacks we discussed, such as the risk of overfitting with high-degree polynomials and the challenges in interpreting higher-order coefficients. You should always consider the trade-off between model complexity and interpretability and validate your polynomial model carefully."
      ],
      "metadata": {
        "id": "JGdb-PN41KYi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "26  What is the general equation for polynomial regression\n",
        "\n",
        "The general equation for polynomial regression of degree $n$$n$ is:\n",
        "\n",
        "$Y = a + b_1X + b_2X^2 + ... + b_nX^n + \\epsilon$$Y = a + b_1X + b_2X^2 + ... + b_nX^n + \\epsilon$\n",
        "\n",
        "Where:\n",
        "\n",
        "$Y$$Y$ is the dependent variable.\n",
        "$X$$X$ is the independent variable.\n",
        "$a$$a$ is the y-intercept.\n",
        "$b_1, b_2, ..., b_n$$b_1, b_2, ..., b_n$ are the coefficients for each power of $X$$X$.\n",
        "$\\epsilon$$\\epsilon$ is the error term.\n",
        "This equation models the relationship between $Y$$Y$ and $X$$X$ as a curve defined by the polynomial terms."
      ],
      "metadata": {
        "id": "SwD4mHLe1WXU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "27. Can polynomial regression be applied to multiple variables\n",
        "Yes, absolutely! Polynomial regression can be extended to include multiple independent variables. When you do this, you not only include polynomial terms for each individual variable but potentially also interaction terms between the polynomial terms of different variables.\n",
        "\n",
        "For example, with two independent variables $X_1$$X_1$ and $X_2$$X_2$, a polynomial regression model of degree 2 could look like this:\n",
        "\n",
        "$Y = a + b_1X_1 + b_2X_2 + b_3X_1^2 + b_4X_2^2 + b_5X_1X_2 + \\epsilon$$Y = a + b_1X_1 + b_2X_2 + b_3X_1^2 + b_4X_2^2 + b_5X_1X_2 + \\epsilon$\n",
        "\n",
        "In this equation:\n",
        "\n",
        "$a$$a$ is the intercept.\n",
        "$b_1$$b_1$ and $b_2$$b_2$ are the coefficients for the linear terms of $X_1$$X_1$ and $X_2$$X_2$.\n",
        "$b_3$$b_3$ and $b_4$$b_4$ are the coefficients for the quadratic terms of $X_1$$X_1$ and $X_2$$X_2$.\n",
        "$b_5$$b_5$ is the coefficient for the interaction term between $X_1$$X_1$ and $X_2$$X_2$.\n",
        "As you can see, the number of terms (and thus coefficients to estimate) can increase rapidly as you add more independent variables and increase the degree of the polynomial.\n",
        "\n",
        "Applying polynomial regression to multiple variables allows you to model complex, curved relationships in higher-dimensional space. However, it also increases the risk of overfitting and makes the model more difficult to interpret."
      ],
      "metadata": {
        "id": "dRU63Ef61ceL"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6f4f91fe"
      },
      "source": [
        "28 What are the limitations of polynomial regression?\n",
        "\n",
        "While polynomial regression offers more flexibility than linear regression for modeling non-linear relationships, it's not without its drawbacks. Here are some of the key limitations:\n",
        "\n",
        "1.  **Risk of Overfitting:** This is perhaps the most significant limitation. As you increase the degree of the polynomial, the model becomes more complex and can fit the training data very closely. However, this can lead to overfitting, where the model captures the noise and random fluctuations in the training data rather than the true underlying relationship. An overfitted model will perform poorly when making predictions on new, unseen data. This risk is even higher when dealing with a limited amount of data.\n",
        "\n",
        "2.  **Interpretation Challenges:** Interpreting the coefficients of higher-order polynomial terms can be less intuitive than interpreting the slope in simple linear regression. The coefficient of $X^2$ or $X^3$ doesn't have a simple \"change in Y for a one-unit change in X\" interpretation in the same way as the linear term. The effect of the independent variable on the dependent variable changes depending on the value of the independent variable.\n",
        "\n",
        "3.  **Extrapolation Issues:** Polynomial models can behave erratically and produce unreliable predictions when extrapolating outside the range of the data used to train the model. The curve fitted within the data range may diverge sharply outside of it, leading to nonsensical predictions.\n",
        "\n",
        "4.  **Sensitivity to Outliers:** Polynomial regression can be quite sensitive to outliers. A single outlier can significantly influence the shape of the fitted curve, especially with higher-degree polynomials, potentially leading to a misleading model.\n",
        "\n",
        "5.  **Choosing the Right Degree:** Deciding on the appropriate degree of the polynomial can be challenging. Choosing too low a degree might result in an underfitted model that doesn't capture the non-linear pattern, while choosing too high a degree can lead to overfitting. This often requires careful model evaluation using techniques like cross-validation.\n",
        "\n",
        "6.  **Multicollinearity (when using multiple variables with polynomial terms):** If you extend polynomial regression to multiple independent variables, including polynomial terms and interaction terms can introduce or increase multicollinearity among the predictors, making coefficient estimates unstable.\n",
        "\n",
        "In summary, while polynomial regression is a valuable tool for modeling non-linear relationships, it's crucial to be mindful of the potential for overfitting, challenges in interpretation, and issues with extrapolation. Careful model selection, validation, and diagnostic checks are essential when using polynomial regression."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "075ee7ee"
      },
      "source": [
        "29.What methods can be used to evaluate model fit when selecting the degree of a polynomial\n",
        "\n",
        "Selecting the appropriate degree for a polynomial regression model is crucial. Choosing too low a degree can lead to underfitting (the model doesn't capture the non-linear pattern), while choosing too high a degree can lead to overfitting (the model fits the noise and performs poorly on new data). Here are some common methods to evaluate model fit and guide the selection of the polynomial degree:\n",
        "\n",
        "1.  **Visual Inspection of Scatter Plots and Fitted Curves:**\n",
        "    *   **How it works:** Plot the data points and overlay the fitted polynomial regression curves for different degrees.\n",
        "    *   **Evaluation:** Visually assess how well each curve fits the overall pattern of the data. Look for curves that capture the trend without being overly wavy or influenced by individual outliers.\n",
        "    *   **Pros:** Simple and intuitive for understanding the relationship.\n",
        "    *   **Cons:** Subjective and can be misleading, especially with noisy data or in higher dimensions.\n",
        "\n",
        "2.  **Residual Plots:**\n",
        "    *   **How it works:** Plot the residuals (difference between observed and predicted values) against the independent variable or the predicted values for different polynomial degrees.\n",
        "    *   **Evaluation:** For a well-fitting model, the residuals should be randomly scattered around zero with no discernible pattern. A clear pattern in the residual plot (e.g., a curve or systematic trend) suggests that the current polynomial degree is not capturing the relationship adequately.\n",
        "    *   **Pros:** Helps diagnose if the linear assumption (on the transformed features) is met and if a higher degree is needed.\n",
        "    *   **Cons:** Requires visual interpretation.\n",
        "\n",
        "3.  **Coefficient of Determination (R²) and Adjusted R²:**\n",
        "    *   **How it works:** Calculate R² and Adjusted R² for models with different polynomial degrees.\n",
        "    *   **Evaluation:** As the polynomial degree increases, R² will typically increase. However, a significant increase in R² might be due to overfitting. Adjusted R² penalizes for the number of predictors (which increases with the polynomial degree). Look for the degree where Adjusted R² plateaus or starts to decrease, as this can indicate that additional polynomial terms are not improving the model's fit on a generalized basis.\n",
        "    *   **Pros:** Quantitative measures of model fit. Adjusted R² helps account for model complexity.\n",
        "    *   **Cons:** Can still be misleading without considering other factors like overfitting.\n",
        "\n",
        "4.  **Cross-Validation:**\n",
        "    *   **How it works:** Split your data into multiple folds. Train the polynomial regression model of a specific degree on a subset of the folds (training folds) and evaluate its performance on the remaining fold(s) (validation fold(s)). Repeat this process for different folds and different polynomial degrees.\n",
        "    *   **Evaluation:** Calculate a performance metric (e.g., Mean Squared Error - MSE, R²) on the validation folds for each degree. Choose the degree that yields the best average performance on the validation sets. This is a more robust method for assessing how well the model generalizes to unseen data and helps detect overfitting.\n",
        "    *   **Pros:** Provides a more reliable estimate of the model's performance on new data and is a good defense against overfitting.\n",
        "    *   **Cons:** Can be computationally more intensive.\n",
        "\n",
        "5.  **Statistical Tests (e.g., F-test to compare nested models):**\n",
        "    *   **How it works:** Compare a model with a lower polynomial degree to a model with a higher polynomial degree (where the lower-degree model is \"nested\" within the higher-degree model). An F-test can be used to determine if the additional higher-order terms significantly improve the model's fit.\n",
        "    *   **Evaluation:** If the F-test is statistically significant (low p-value), it suggests that the higher-degree terms add significant explanatory power.\n",
        "    *   **Pros:** Provides a formal statistical test for the significance of adding higher-order terms.\n",
        "    *   **Cons:** Requires understanding of statistical testing and the concept of nested models.\n",
        "\n",
        "**General Approach:**\n",
        "\n",
        "A common approach is to start with visual inspection and R²/Adjusted R² to get an initial idea of appropriate degrees. Then, use cross-validation as a more robust method to select the degree that provides the best balance between fitting the training data and generalizing to new data. Residual plots should also be examined for the chosen model to ensure that the assumptions are reasonably met."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "31 How is polynomial regression implemented in Python?"
      ],
      "metadata": {
        "id": "FVsJJO0b2m5i"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "18d8dded",
        "outputId": "56be38e3-31d7-4b33-cf5e-a16bd6251096"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# 1. Generate some sample data with a non-linear relationship\n",
        "np.random.seed(0)\n",
        "X = 2 * np.random.rand(100, 1)\n",
        "y = 4 + 3 * X**2 + np.random.randn(100, 1) # Quadratic relationship with some noise\n",
        "\n",
        "# Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Visualize the data\n",
        "plt.scatter(X_train, y_train)\n",
        "plt.xlabel(\"X\")\n",
        "plt.ylabel(\"y\")\n",
        "plt.title(\"Sample Data with Non-linear Relationship\")\n",
        "plt.show()"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f53897af"
      },
      "source": [
        "Here's the first step: generating some sample data that exhibits a non-linear (quadratic in this case) relationship and visualizing it. This helps us see why a simple linear model wouldn't be the best fit."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3f16201b",
        "outputId": "e6651e67-7a2d-4660-f6ae-c79e77489fa2"
      },
      "source": [
        "# 2. Transform the data to create polynomial features\n",
        "# We'll create quadratic features (degree=2)\n",
        "poly_features = PolynomialFeatures(degree=2, include_bias=False)\n",
        "X_train_poly = poly_features.fit_transform(X_train)\n",
        "X_test_poly = poly_features.transform(X_test)\n",
        "\n",
        "print(\"Original X_train shape:\", X_train.shape)\n",
        "print(\"Transformed X_train_poly shape:\", X_train_poly.shape)\n",
        "print(\"\\nSample of original X_train:\\n\", X_train[:5])\n",
        "print(\"\\nSample of transformed X_train_poly (X and X^2):\\n\", X_train_poly[:5])"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original X_train shape: (80, 1)\n",
            "Transformed X_train_poly shape: (80, 2)\n",
            "\n",
            "Sample of original X_train:\n",
            " [[0.32261904]\n",
            " [1.15189299]\n",
            " [0.28670657]\n",
            " [1.39526239]\n",
            " [0.19219682]]\n",
            "\n",
            "Sample of transformed X_train_poly (X and X^2):\n",
            " [[0.32261904 0.10408304]\n",
            " [1.15189299 1.32685746]\n",
            " [0.28670657 0.08220066]\n",
            " [1.39526239 1.94675714]\n",
            " [0.19219682 0.03693962]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2821cc7d"
      },
      "source": [
        "Next, we use `PolynomialFeatures` from scikit-learn to transform our independent variable `X` into polynomial features. For a degree of 2, this will create two features: the original `X` and `X^2`. `include_bias=False` is used because the Linear Regression model will add its own intercept."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d2a7cf46",
        "outputId": "cf0144ab-285d-48fd-f1f6-18fc016b4b60"
      },
      "source": [
        "# 3. Fit a Linear Regression model to the polynomial features\n",
        "lin_reg = LinearRegression()\n",
        "lin_reg.fit(X_train_poly, y_train)\n",
        "\n",
        "# Print the coefficients\n",
        "print(\"Intercept:\", lin_reg.intercept_)\n",
        "print(\"Coefficients (for X and X^2):\", lin_reg.coef_)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Intercept: [3.93819662]\n",
            "Coefficients (for X and X^2): [[0.89837166 2.52895964]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a69b1a2c"
      },
      "source": [
        "Now, we fit a standard `LinearRegression` model, but instead of fitting it to the original `X`, we fit it to the `X_train_poly` which contains our polynomial features. The `LinearRegression` model finds the best coefficients for the equation $Y = a + b_1X + b_2X^2$."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "a3812b97",
        "outputId": "bf0007ce-4e17-4763-f7f5-fe75546439c3"
      },
      "source": [
        "# 4. Make predictions and visualize the polynomial regression line\n",
        "X_new = np.linspace(0, 2, 100).reshape(100, 1)\n",
        "X_new_poly = poly_features.transform(X_new)\n",
        "y_new_pred = lin_reg.predict(X_new_poly)\n",
        "\n",
        "plt.scatter(X_train, y_train, label='Training data')\n",
        "plt.scatter(X_test, y_test, color='red', label='Testing data')\n",
        "plt.plot(X_new, y_new_pred, color='green', linewidth=3, label='Polynomial Regression Fit (Degree 2)')\n",
        "plt.xlabel(\"X\")\n",
        "plt.ylabel(\"y\")\n",
        "plt.title(\"Polynomial Regression\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "99f12e37"
      },
      "source": [
        "Finally, we make predictions using the fitted model and visualize the results. You can see that the polynomial regression line (green curve) now fits the non-linear data much better than a simple straight line would."
      ]
    }
  ]
}